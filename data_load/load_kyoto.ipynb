{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ACTIVITY = 'activity'\n",
    "DEVICE = 'device'\n",
    "START_TIME = 'start_time'\n",
    "END_TIME = 'end_time'\n",
    "\n",
    "TIME = 'time'\n",
    "VALUE = 'value'\n",
    "NAME = 'name'\n",
    "\n",
    "def _fix_line(s, i):\n",
    "\n",
    "        if i == 2082109:\n",
    "            # Activity work end was not begun in the first place -> remove Activity \n",
    "            s = s[:-2]\n",
    "        if i == 2082361:\n",
    "            # Activity work begins but never ends -> remove Activity\n",
    "            s = s[:-2]\n",
    "\n",
    "        return s\n",
    "\n",
    "def _get_devices_df(df):\n",
    "    df = df.copy().drop(ACTIVITY, axis=1)\n",
    "    bin_mask = (df[VALUE] == 'ON') | (df[VALUE] == 'OFF')\n",
    "\n",
    "    # preprocess only binary devices to ON-OFF--> False True\n",
    "    df_binary = df[bin_mask]\n",
    "    df_binary[VALUE] = (df_binary[VALUE] == 'ON')\n",
    "\n",
    "    # preprocess only numeric devices\n",
    "    num_mask = pd.to_numeric(df[VALUE], errors='coerce').notnull()\n",
    "    df_num = df[num_mask]\n",
    "    df_num[VALUE] = df_num[VALUE].astype(float)\n",
    "\n",
    "    # preprocess categorical devices\n",
    "    df_cat = df[~num_mask & ~bin_mask]\n",
    "\n",
    "    # join datasets\n",
    "    df = pd.concat([df_cat, df_binary, df_num], axis=0, ignore_index=True)\n",
    "    df.columns = [TIME, DEVICE, VALUE]\n",
    "    df = df.sort_values(by=TIME).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _get_activity_df(df):\n",
    "    # get all rows containing activities\n",
    "    df = df.copy()[~df[ACTIVITY].isnull()][[START_TIME, ACTIVITY]]\n",
    "    df[ACTIVITY] = df[ACTIVITY].astype(str).apply(lambda x: x.strip())\n",
    "\n",
    "    act_list = list(df[ACTIVITY].unique())\n",
    "    act_list.sort()\n",
    "    \n",
    "    new_df_lst = []\n",
    "    for i in range(1, len(act_list), 2):\n",
    "        activity = ' '.join(act_list[i].split(' ')[:-1])\n",
    "        act_begin = act_list[i-1]\n",
    "        act_end = act_list[i]\n",
    "        assert activity in act_begin and activity in act_end\n",
    "           \n",
    "        # create subsets for begin and end of chosen activity\n",
    "        df_res = df[df[ACTIVITY] == act_begin].reset_index(drop=True)\n",
    "        df_end = df[df[ACTIVITY] == act_end].reset_index(drop=True)\n",
    "        #assert len(df_res) == len(df_end)\n",
    "        \n",
    "        # append sorted end_time to start_time as they should be\n",
    "        # pairwise together\n",
    "        df_res[ACTIVITY] = activity\n",
    "        df_res[END_TIME] = df_end[START_TIME]\n",
    "        new_df_lst.append(df_res)\n",
    "    \n",
    "    # data preparation\n",
    "    res = pd.concat(new_df_lst)\n",
    "    res = res.reindex(columns=[START_TIME, END_TIME, ACTIVITY])\n",
    "    res = res.sort_values(START_TIME)\n",
    "    res = res.reset_index(drop=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityDict(dict):\n",
    "    \"\"\" Dictionary with activity pd.DataFrames as values and subject names as keys.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obj=None):\n",
    "\n",
    "        if isinstance(obj, pd.DataFrame):\n",
    "            obj = obj.copy().reset_index(drop=True)\n",
    "            super().__init__({'subject': obj})\n",
    "        elif isinstance(obj, list):\n",
    "            if isinstance(obj[0], tuple):\n",
    "                super().__init__({name: df for (name, df) in obj})\n",
    "            else:\n",
    "                super().__init__({f'subject_{i}': df for i, df in enumerate(obj)})\n",
    "        elif isinstance(obj, ActivityDict) or isinstance(obj, dict):\n",
    "            super().__init__(obj)\n",
    "        else:\n",
    "            super().__init__()\n",
    "\n",
    "    def subjects(self) -> list:\n",
    "        return list(self.keys())\n",
    "\n",
    "    def to_json(self, date_unit=\"ns\"):\n",
    "        \"\"\"Serialize to json\"\"\"\n",
    "        tmp = {}\n",
    "        for k, df in self.items():\n",
    "            tmp[k] = df.to_json(date_unit=date_unit)\n",
    "\n",
    "        return json.dumps(tmp)\n",
    "\n",
    "    def read_json(cls, string):\n",
    "        \"\"\"Serialize from json\"\"\"\n",
    "        tmp = json.loads(string)\n",
    "        for k, str in tmp.items():\n",
    "            tmp[k] = pd.read_json(str)\n",
    "        return ActivityDict(tmp)\n",
    "\n",
    "    def nr_acts(self):\n",
    "        \"\"\"\"\"\"\n",
    "        return max([len(df_acts[ACTIVITY].unique()) for df_acts in self.values()])\n",
    "\n",
    "    def get_activity_union(self):\n",
    "        return list(set([item for v in self.values()\n",
    "                         for item in v[ACTIVITY].unique()]))\n",
    "\n",
    "    def apply(self, func):\n",
    "        \"\"\" Applies a function to each dataframe\n",
    "        \"\"\"\n",
    "        for k, df in self.items():\n",
    "            self[k] = func(df)\n",
    "        return self\n",
    "\n",
    "    def min_starttime(self):\n",
    "        min_lst = []\n",
    "        for df_acts in self.values():\n",
    "            if not df_acts.empty:\n",
    "                min_lst.append(df_acts[START_TIME].iloc[0])\n",
    "        return min(min_lst)\n",
    "\n",
    "    def max_endtime(self):\n",
    "        max_lst = []\n",
    "        for df_acts in self.values():\n",
    "            if not df_acts.empty:\n",
    "                max_lst.append(df_acts[END_TIME].iloc[-1])\n",
    "        return max(max_lst)\n",
    "\n",
    "    def concat(self):\n",
    "        return pd.concat(self.values())\n",
    "\n",
    "    def copy(self):\n",
    "        \"\"\" Returns a deep copy of itsself\n",
    "        \"\"\"\n",
    "        return ActivityDict({k: v.copy() for k, v in self.items()})\n",
    "\n",
    "    @classmethod\n",
    "    def wrap(cls, df_acts):\n",
    "        if isinstance(df_acts, pd.DataFrame):\n",
    "            df_acts = df_acts.copy().reset_index(drop=True)  # TODO not here\n",
    "            df_acts = ActivityDict({'subject': df_acts})\n",
    "            return df_acts\n",
    "        elif isinstance(df_acts, list):\n",
    "            return ActivityDict({f'subject_{i}': df for i, df in enumerate(df_acts)})\n",
    "        elif isinstance(df_acts, ActivityDict):\n",
    "            return df_acts\n",
    "        elif isinstance(df_acts, dict):\n",
    "            return ActivityDict(df_acts)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def unwrap(self, inst_type: type):\n",
    "        if inst_type == ActivityDict:\n",
    "            return self\n",
    "        elif inst_type == list:\n",
    "            return list(self.values())\n",
    "        elif inst_type == dict:\n",
    "            return super(self)\n",
    "        elif inst_type == pd.DataFrame:\n",
    "            assert len(self) == 1\n",
    "            return list(self.values())[0]\n",
    "        else:\n",
    "            raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kyoto_dataset(data_dir: str):\n",
    "    data_dir = Path(data_dir)\n",
    "\n",
    "    raw_path = data_dir / 'data'\n",
    "    corrected_path = data_dir / 'corrected_data.csv'\n",
    "    \n",
    "    with open(raw_path, 'r') as f_o, open(corrected_path, 'w') as f_t:\n",
    "            delimiter = ';'\n",
    "            for i, line in enumerate(f_o.readlines()):\n",
    "\n",
    "                # Seperate with tabs and whitespaces and remove empty sets\n",
    "                s = [sub.split(' ') for sub in line[:-1].split('\\t')]\n",
    "                s = [subsub for sub in s for subsub in sub]\n",
    "                s = [item for item in s if item != '']\n",
    "\n",
    "                if not s:\n",
    "                    # the case for empty lines\n",
    "                    continue\n",
    "\n",
    "                # Join timestamp\n",
    "                s = [' '.join([s[0], s[1]])] + s[2:]\n",
    "\n",
    "                try:\n",
    "                    s = _fix_line(s, i)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "                new_line = delimiter.join(s[:3])\n",
    "\n",
    "                try:\n",
    "                    s[4] # test if there is an activity\n",
    "                    new_line += delimiter + \" \".join(s[3:])\n",
    "                except IndexError as e:\n",
    "                    pass\n",
    "\n",
    "                f_t.write(new_line + \"\\n\")\n",
    "            f_t.close()\n",
    "            f_o.close()\n",
    "    \n",
    "    df = pd.read_csv(corrected_path,\n",
    "                    sep=';',\n",
    "                    infer_datetime_format=True,\n",
    "                    na_values=True,\n",
    "                    names=[START_TIME, 'id', VALUE, ACTIVITY],\n",
    "                    )\n",
    "    print(df.iloc[72122:72126])\n",
    "    # df[START_TIME] = df[START_TIME].apply(lambda x: x.strip())\n",
    "    df[START_TIME] = pd.to_datetime(df[START_TIME],format=\"mixed\")\n",
    "    df = df.sort_values(by=START_TIME)\\\n",
    "           .drop_duplicates()\n",
    "    # Drop when a device is na \n",
    "    df = df[~df.iloc[:, :3].isna().any(axis=1)].reset_index(drop=True)\n",
    "    df_dev = _get_devices_df(df)\n",
    "    df_act = _get_activity_df(df)\n",
    "    \n",
    "\n",
    "    lst_act_res1 = [\n",
    "        'R1_Wandering_in_room',\n",
    "        'R1_Sleep',\n",
    "        'R1_Bed_Toilet_Transition',\n",
    "        'R1_Personal_Hygiene',\n",
    "        'R1_Bathing',\n",
    "        'R1_Work',\n",
    "        'R1_Meal_Preparation',\n",
    "        'R1_Leave_Home',\n",
    "        'R1_Enter_Home',\n",
    "        'R1_Eating',\n",
    "        'R1_Watch_TV',\n",
    "        'R1_Housekeeping',\n",
    "        'R1_Sleeping_Not_in_Bed'\n",
    "    ]\n",
    "    lst_act_res2 = [\n",
    "        'R2_Wandering_in_room',\n",
    "        'R2_Meal_Preparation',\n",
    "        'R2_Eating',\n",
    "        'R2_Work',\n",
    "        'R2_Bathing',\n",
    "        'R2_Leave_Home',\n",
    "        'R2_Watch_TV',\n",
    "        'R2_Bed_Toilet_Transition',\n",
    "        'R2_Enter_Home',\n",
    "        'R2_Sleep',\n",
    "        'R2_Personal_Hygiene',\n",
    "        'R2_Sleeping_Not_in_Bed'\n",
    "    ]\n",
    "    dct_act = ActivityDict({\n",
    "        'resident_1': df_act[df_act[ACTIVITY].isin(lst_act_res1)],\n",
    "        'resident_2': df_act[df_act[ACTIVITY].isin(lst_act_res2)],\n",
    "        })\n",
    "\n",
    "    lst_act = df_act[ACTIVITY].unique()\n",
    "    lst_dev = df_dev[DEVICE].unique()\n",
    "\n",
    "    lst_act = df_act[ACTIVITY].unique()\n",
    "    lst_dev = df_dev[DEVICE].unique()\n",
    "\n",
    "    return dict(\n",
    "        activities=dct_act,\n",
    "        devices=df_dev,\n",
    "        activity_list=lst_act,\n",
    "        device_list=lst_dev\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leave\\AppData\\Local\\Temp\\ipykernel_50736\\396841880.py:40: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(corrected_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       start_time    id value activity\n",
      "72122  2009-08-30 10:44:06.083411  M048    ON      NaN\n",
      "72123  2009-08-30 10:44:46.026873  P001  4727      NaN\n",
      "72124  2009-08-30 10:44:52.005653  M046    ON      NaN\n",
      "72125         2009-08-30 10:44:53  M047    ON      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leave\\AppData\\Local\\Temp\\ipykernel_50736\\1628173865.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_binary[VALUE] = (df_binary[VALUE] == 'ON')\n",
      "C:\\Users\\leave\\AppData\\Local\\Temp\\ipykernel_50736\\1628173865.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_num[VALUE] = df_num[VALUE].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activities:\n",
      "                  start_time                   end_time              activity\n",
      "0 2009-08-24 00:00:19.034964 2009-08-24 00:04:36.042376  R1_Wandering_in_room\n",
      "1 2009-08-24 00:04:38.039369 2009-08-24 00:05:21.041611              R1_Sleep\n",
      "2 2009-08-24 00:05:23.013091 2009-08-24 00:08:30.090362  R1_Wandering_in_room\n",
      "3 2009-08-24 00:08:31.034365 2009-08-24 00:10:14.017269              R1_Sleep\n",
      "5 2009-08-24 00:15:47.003067 2009-08-24 00:16:27.004872              R1_Sleep\n",
      "                   start_time                   end_time              activity\n",
      "4  2009-08-24 00:15:25.059479 2009-08-24 07:07:50.044921              R2_Sleep\n",
      "17 2009-08-24 07:07:57.081426 2009-08-24 07:10:43.063058   R2_Personal_Hygiene\n",
      "19 2009-08-24 07:11:07.052461 2009-08-24 07:43:18.019302              R2_Sleep\n",
      "20 2009-08-24 07:43:21.019996 2009-08-24 07:47:09.082372  R2_Wandering_in_room\n",
      "21 2009-08-24 07:47:34.061355 2009-08-24 07:53:53.087228   R2_Meal_Preparation\n",
      "\n",
      "Devices:\n",
      "                        time device  value\n",
      "0 2009-08-24 00:00:00.000009   M046  False\n",
      "1 2009-08-24 00:00:01.039408   M048  False\n",
      "2 2009-08-24 00:00:19.034964   M050   True\n",
      "3 2009-08-24 00:00:19.078563   M044   True\n",
      "4 2009-08-24 00:00:21.029362   M046   True\n"
     ]
    }
   ],
   "source": [
    "dataset = load_kyoto_dataset(Path(\"../dataset/casas/kyoto2010\"))\n",
    "\n",
    "print(\"Activities:\")\n",
    "print(dataset['activities']['resident_1'].head())\n",
    "print(dataset['activities']['resident_2'].head())\n",
    "\n",
    "print(\"\\nDevices:\")\n",
    "print(dataset['devices'].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
